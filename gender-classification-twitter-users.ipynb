{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Task for Who Sex Of Users On Twitter.......Gender(Female , Male)\n","## Twitter User Gender Prediction  \n","مجموعة بيانات لمستخدمي تويتر ونحاول تصنيف جنس مستخدمي معين......\n","استنادا الي سلسلة من البيانات من خلال بيانات معدلة يدويا ثم التصنيف البيانات من خلال المستخدمين لتويتر.........بنطلب من المستخدمين الدخول وتحديد جنس المستخدمين من خلال الملف الشخصي ليهم ..بحيث يكون عندنا نوع جنس المستخدم  وعمود الثقة بين النوعين  \n","من خلال ثلاث انواع محتملة لمعرفة النوع وتنقسم الي 1- ذكر 2-انثي 3-العلامة التجارية\n","ونحدده علي حسب سجل معين من خلال مجموعة من المميزات ززززززززز\n","هنستخدم شبكة عصبية متكررة ذات مداخل متعددة\n","كما اننا سنستخدم الكود بايثون لعمل ذالك باستخدام الخوارزميات والكتبات التي تخص بايثون  والتي نستخدمها في مجال تحليل البيانات وتعلم الاله.................. \n","\n","A data set of Twitter users and trying to categorize the gender of specific users...\n","Based on a series of data through manually modified data and then categorizing the data through Twitter users....... We ask users to enter and specify the gender of users through their profile.. so that we have the user's gender and the confidence column between the two types\n","Through three possible types to know the gender, they are divided into 1- Male 2- Female 3- Brand\n","And we define it according to a specific record through a set of features\n","We will use a recurrent neural network with multiple inputs\n","We will also use Python code to do this using Python-specific algorithms and scripts that we use in the field of data analysis and machine learning.\n","Given *data about users on Twitter*, let's try to predict the **gender** of a given user.  \n","  \n","We will use a deep recurrent neural network with multiple inputs to make our predictions."]},{"cell_type":"markdown","metadata":{},"source":["# Getting Started Code"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.model_selection import train_test_split\n","\n","import tensorflow as tf\n","\n","from sklearn.metrics import confusion_matrix, classification_report"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data = pd.read_csv('../input/twitter-user-gender-classification/gender-classifier-DFE-791531.csv', encoding='latin-1')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data.info()"]},{"cell_type":"markdown","metadata":{},"source":["# Preprocessing On Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["data.isna().mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_sequences(texts, vocab_length):\n","    tokenizer = Tokenizer(num_words=vocab_length)\n","    tokenizer.fit_on_texts(texts)\n","    \n","    sequences = tokenizer.texts_to_sequences(texts)\n","    \n","    max_seq_length = np.max([len(sequence) for sequence in sequences])\n","    \n","    sequences = pad_sequences(sequences, maxlen=max_seq_length, padding='post')\n","    \n","    return sequences"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["np.int('ED', 16)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def hex_to_decimal(x):\n","    try:\n","        return np.int(x, 16)\n","    except:\n","        return 0\n","\n","def get_rgb(colors):\n","    r = colors.apply(lambda x: hex_to_decimal(x[0:2]))\n","    g = colors.apply(lambda x: hex_to_decimal(x[2:4]))\n","    b = colors.apply(lambda x: hex_to_decimal(x[4:6]))\n","    return r, g, b"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def preprocess_inputs(df):\n","    df = df.copy()\n","    \n","    # Drop unnecessary columns\n","    df = df.drop(['_unit_id', 'name', 'profileimage', 'tweet_id'], axis=1)\n","    \n","    # Encode unknown values in the target column as np.NaN\n","    df['gender'] = df['gender'].replace('unknown', np.NaN)\n","    \n","    # Drop rows with missing target values\n","    gender_nas = df[df['gender'].isna()].index\n","    df = df.drop(gender_nas, axis=0).reset_index(drop=True)\n","    \n","    # Drop columns with over 30% missing values\n","    missing_cols = df.columns[df.isna().mean() > 0.3]\n","    df = df.drop(missing_cols, axis=1)\n","    \n","    # There are only 50 remaining missing values in the _last_judgment_at columns, so let's drop those rows\n","    judgment_nas = df[df['_last_judgment_at'].isna()].index\n","    df = df.drop(judgment_nas, axis=0).reset_index(drop=True)\n","    \n","    # Let's encode the missing values in the description column as empty strings\n","    df['description'] = df['description'].fillna('')\n","    \n","    # Create date/time columns\n","    for column in ['_last_judgment_at', 'created', 'tweet_created']:\n","        df[column] = pd.to_datetime(df[column])\n","    \n","    df['judgment_day'] = df['_last_judgment_at'].apply(lambda x: x.day)\n","    df['judgment_hour'] = df['_last_judgment_at'].apply(lambda x: x.hour)\n","    \n","    df['created_year'] = df['created'].apply(lambda x: x.year)\n","    df['created_month'] = df['created'].apply(lambda x: x.month)\n","    df['created_day'] = df['created'].apply(lambda x: x.day)\n","    df['created_hour'] = df['created'].apply(lambda x: x.hour)\n","    \n","    df['tweet_hour'] = df['tweet_created'].apply(lambda x: x.hour)\n","    \n","    df = df.drop(['_last_judgment_at', 'created', 'tweet_created'], axis=1)\n","    \n","    # Get sequence data for description and text columns\n","    desc = get_sequences(df['description'], vocab_length=20000)\n","    tweets = get_sequences(df['text'], vocab_length=20000)\n","    \n","    df = df.drop(['description', 'text'], axis=1)\n","    \n","    # Drop columns with only one value\n","    df = df.drop(['_golden', '_unit_state', '_trusted_judgments', 'profile_yn'], axis=1)\n","    \n","    # Encode color columns as RGB values\n","    df['link_red'], df['link_green'], df['link_blue'] = get_rgb(df['link_color'])\n","    df['side_red'], df['side_green'], df['side_blue'] = get_rgb(df['sidebar_color'])\n","    \n","    df = df.drop(['link_color', 'sidebar_color'], axis=1)\n","    \n","    # Encode label column\n","    label_mapping = {'female': 0, 'male': 1, 'brand': 2}\n","    df['gender'] = df['gender'].replace(label_mapping)\n","    \n","    # Split df into X and y\n","    y = df['gender'].copy()\n","    X = df.drop('gender', axis=1).copy()\n","    \n","    # Scale X with a standard scaler\n","    scaler = StandardScaler()\n","    X = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n","    \n","    return X, desc, tweets, y"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X, desc, tweets, y = preprocess_inputs(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["{column: len(X[column].unique()) for column in X.columns}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["desc.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["tweets.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y.value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["# Train-Test Split"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["X_train, X_test, desc_train, desc_test, tweets_train, tweets_test, y_train, y_test = \\\n","    train_test_split(X, desc, tweets, y, train_size=0.7, random_state=1)"]},{"cell_type":"markdown","metadata":{},"source":["# Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["desc.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def build_model():\n","\n","    X_inputs = tf.keras.Input(shape=(X.shape[1],))\n","    desc_inputs = tf.keras.Input(shape=(desc.shape[1],))\n","    tweet_inputs = tf.keras.Input(shape=(tweets.shape[1],))\n","\n","    # X\n","    X_dense1 = tf.keras.layers.Dense(256, activation='relu')(X_inputs)\n","    X_dense2 = tf.keras.layers.Dense(256, activation='relu')(X_dense1)\n","\n","    # desc\n","    desc_embedding = tf.keras.layers.Embedding(\n","        input_dim=20000,\n","        output_dim=256,\n","        input_length=desc.shape[1]\n","    )(desc_inputs)\n","    desc_gru = tf.keras.layers.GRU(256, return_sequences=False)(desc_embedding)\n","    desc_flatten = tf.keras.layers.Flatten()(desc_embedding)\n","    desc_concat = tf.keras.layers.concatenate([desc_gru, desc_flatten])\n","\n","    # tweets\n","    tweet_embedding = tf.keras.layers.Embedding(\n","        input_dim=20000,\n","        output_dim=256,\n","        input_length=tweets.shape[1]\n","    )(tweet_inputs)\n","    tweet_gru = tf.keras.layers.GRU(256, return_sequences=False)(tweet_embedding)\n","    tweet_flatten = tf.keras.layers.Flatten()(tweet_embedding)\n","    tweet_concat = tf.keras.layers.concatenate([tweet_gru, tweet_flatten])\n","\n","    concat = tf.keras.layers.concatenate([X_dense2, desc_concat, tweet_concat])\n","\n","    outputs = tf.keras.layers.Dense(3, activation='softmax')(concat)\n","\n","\n","    model = tf.keras.Model(inputs=[X_inputs, desc_inputs, tweet_inputs], outputs=outputs)\n","\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model = build_model()\n","\n","print(model.summary())\n","tf.keras.utils.plot_model(model)"]},{"cell_type":"markdown","metadata":{},"source":["# Training On Model"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.compile(\n","    optimizer='adam',\n","    loss='sparse_categorical_crossentropy',\n","    metrics=['accuracy']\n",")\n","\n","batch_size = 32\n","epochs = 3\n","\n","history = model.fit(\n","    [X_train, desc_train, tweets_train],\n","    y_train,\n","    validation_split=0.2,\n","    batch_size=batch_size,\n","    epochs=epochs,\n","    callbacks=[\n","        tf.keras.callbacks.ModelCheckpoint('./model.h5', save_best_only=True, save_weights_only=True),\n","        tf.keras.callbacks.ReduceLROnPlateau()\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model.load_weights('./model.h5')"]},{"cell_type":"markdown","metadata":{},"source":["# Results For Data"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["results = model.evaluate([X_test, desc_test, tweets_test], y_test, verbose=0)\n","print(\"Model Accuracy: {:.2f}%\".format(results[1] * 100))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["y_true = np.array(y_test)\n","\n","y_pred = model.predict([X_test, desc_test, tweets_test])\n","y_pred = map(lambda x: np.argmax(x), y_pred)\n","y_pred = np.array(list(y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["cm = confusion_matrix(y_true, y_pred)\n","clr = classification_report(y_true, y_pred, target_names=['Female', 'Male', 'Brand'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plt.figure(figsize=(6, 6))\n","sns.heatmap(cm, annot=True, fmt='g', cbar=False, cmap='Blues')\n","plt.xticks(np.arange(3) + 0.5, ['Female', 'Male', 'Brand'])\n","plt.yticks(np.arange(3) + 0.5, ['Female', 'Male', 'Brand'])\n","plt.xlabel(\"Predicted\")\n","plt.ylabel(\"Actual\")\n","plt.title(\"Confusion Matrix\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(\"Classification Report:\\n\\n\", clr)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
